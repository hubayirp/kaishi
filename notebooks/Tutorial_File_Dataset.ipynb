{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File datasets\n",
    "If there's a particular data type you are working with, it's usually better to use the type-specific dataset object. However, there are still a few core operations that can be performed on generic files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing datasets\n",
    "Let's start by creating a simple dataset of text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "outdir = \"toy_files\"\n",
    "os.mkdir(outdir)\n",
    "\n",
    "file1 = \"file1_contents\"\n",
    "file2 = \"file2_contents\"\n",
    "file2_duplicate = \"file2_contents\"\n",
    "file3 = \"file3_contents\"\n",
    "with open(outdir + \"/1.file\", \"w\") as fd:\n",
    "    fd.write(file1)\n",
    "with open(outdir + \"/2.file\", \"w\") as fd:\n",
    "    fd.write(file2)\n",
    "with open(outdir + \"/2_dup.file\", \"w\") as fd:\n",
    "    fd.write(file2_duplicate)\n",
    "with open(outdir + \"/3.file\", \"w\") as fd:\n",
    "    fd.write(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file list:\n",
      "+-------+------------+------------------------+--------+\n",
      "| Index | File Name  | Children               | Labels |\n",
      "+-------+------------+------------------------+--------+\n",
      "|   0   |   3.file   |     {'duplicates': []} |   []   |\n",
      "|   1   |   2.file   |     {'duplicates': []} |   []   |\n",
      "|   2   | 2_dup.file |     {'duplicates': []} |   []   |\n",
      "|   3   |   1.file   |     {'duplicates': []} |   []   |\n",
      "+-------+------------+------------------------+--------+\n",
      "Filtered files:\n",
      "+-----------+---------------+\n",
      "| File Name | Filter Reason |\n",
      "+-----------+---------------+\n",
      "+-----------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from kaishi.core.dataset import FileDataset\n",
    "fd = FileDataset(outdir)\n",
    "fd.file_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File procesing pipelines\n",
    "There are fewer components available for files compared to other types, as the other types inherit from the FileGroup class. However, there are still plenty of options available to perform some common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FilterByLabel',\n",
       " 'FilterByRegex',\n",
       " 'FilterDuplicateFiles',\n",
       " 'FilterSubsample',\n",
       " 'LabelerValidationAndTest']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.get_pipeline_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaishi pipeline: \n",
      "0: FilterDuplicateFiles\n",
      "1: FilterSubsample\n",
      "     N: None\n",
      "     seed: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fd.configure_pipeline([\"FilterDuplicateFiles\", \"FilterSubsample\"])\n",
    "print(fd.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaishi pipeline: \n",
      "0: FilterDuplicateFiles\n",
      "1: FilterSubsample\n",
      "     N: 2\n",
      "     seed: 42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fd.pipeline.components[1].configure(N=2, seed=42)\n",
    "print(fd.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current file list:\n",
      "+-------+-----------+----------------------------------+--------+\n",
      "| Index | File Name | Children                         | Labels |\n",
      "+-------+-----------+----------------------------------+--------+\n",
      "|   0   |   3.file  |     {'duplicates': []}           |   []   |\n",
      "|   1   |   2.file  |     {'duplicates': [2_dup.file]} |   []   |\n",
      "+-------+-----------+----------------------------------+--------+\n",
      "Filtered files:\n",
      "+------------+---------------+\n",
      "| File Name  | Filter Reason |\n",
      "+------------+---------------+\n",
      "| 2_dup.file |   duplicates  |\n",
      "|   1.file   |   subsample   |\n",
      "+------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "fd.run_pipeline()\n",
    "fd.file_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
